{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3799bdcb",
   "metadata": {},
   "source": [
    "# NL2SQL Pipeline Demo - Step by Step\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the **Natural Language to SQL (NL2SQL)** pipeline capabilities.\n",
    "\n",
    "### What This Pipeline Does:\n",
    "1. üß† **Extract Intent & Entities** from natural language questions\n",
    "2. üìä **Read Database Schema** to understand available tables and relationships\n",
    "3. ‚ö° **Generate T-SQL** queries using AI (Azure OpenAI)\n",
    "4. üîç **Sanitize & Validate** the generated SQL\n",
    "5. üéØ **Execute** against Azure SQL Database\n",
    "6. üìà **Format & Display** results with token usage and cost tracking\n",
    "\n",
    "### Technologies Used:\n",
    "- **Azure OpenAI** (GPT-4 or GPT-5/o-series models)\n",
    "- **LangChain** for AI orchestration\n",
    "- **Azure SQL Database** for data storage\n",
    "- **Python 3.11+**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a98b1d",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Dependencies and Load Configuration\n",
    "\n",
    "First, we'll import all necessary libraries and load our Azure credentials from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f72e45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Dependencies loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8d0d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Configure Azure OpenAI Connection\n",
    "\n",
    "We'll set up the connection to Azure OpenAI and detect whether we're using a reasoning model (o-series/GPT-5) or a standard model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cafd3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "ü§ñ MODEL CONFIGURATION\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "Deployment: gpt-4.1\n",
      "Type: Standard Model\n",
      "Endpoint: https://aq-ai-foundry-sweden-central.openai.azure.com/\n",
      "API Version: 2025-04-01-preview\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAI configuration\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-04-01-preview\")\n",
    "\n",
    "# Helper: detect reasoning models (o-series and gpt-5)\n",
    "def _is_reasoning_like_model(deployment_name: str | None) -> bool:\n",
    "    name = (deployment_name or \"\").lower()\n",
    "    return name.startswith(\"o\") or name.startswith(\"gpt-5\")\n",
    "\n",
    "_USING_REASONING_STYLE = _is_reasoning_like_model(DEPLOYMENT_NAME)\n",
    "\n",
    "# Display configuration\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"ü§ñ MODEL CONFIGURATION\")\n",
    "print(\"‚ïê\" * 60)\n",
    "print(f\"Deployment: {DEPLOYMENT_NAME}\")\n",
    "print(f\"Type: {'Reasoning Model (o-series/GPT-5)' if _USING_REASONING_STYLE else 'Standard Model'}\")\n",
    "print(f\"Endpoint: {ENDPOINT}\")\n",
    "print(f\"API Version: {API_VERSION}\")\n",
    "print(\"‚ïê\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa40fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Initialize the LLM\n",
    "\n",
    "Create the Language Model instance. For reasoning models, we use direct API calls. For standard models, we use LangChain's wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc8837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain LLM initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "def _make_llm():\n",
    "    \"\"\"Create an LLM instance based on model type.\"\"\"\n",
    "    if _USING_REASONING_STYLE:\n",
    "        return None  # Use direct Azure Chat Completions calls\n",
    "    return AzureChatOpenAI(\n",
    "        openai_api_key=API_KEY,\n",
    "        azure_endpoint=ENDPOINT,\n",
    "        deployment_name=DEPLOYMENT_NAME,\n",
    "        api_version=API_VERSION,\n",
    "        max_tokens=8192,\n",
    "    )\n",
    "\n",
    "llm = _make_llm()\n",
    "\n",
    "if llm:\n",
    "    print(\"‚úÖ LangChain LLM initialized successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Direct API mode enabled for reasoning model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd22a6",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Token Usage Tracking\n",
    "\n",
    "Set up token usage tracking to monitor costs and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8939f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Token tracking initialized!\n"
     ]
    }
   ],
   "source": [
    "# Token usage accumulator\n",
    "_TOKEN_USAGE = {\"prompt\": 0, \"completion\": 0, \"total\": 0}\n",
    "\n",
    "def _accumulate_usage(usage: Optional[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Accumulate token usage across all API calls.\"\"\"\n",
    "    if not usage:\n",
    "        return\n",
    "    _TOKEN_USAGE[\"prompt\"] += int(usage.get(\"prompt_tokens\", 0) or 0)\n",
    "    _TOKEN_USAGE[\"completion\"] += int(usage.get(\"completion_tokens\", 0) or 0)\n",
    "    _TOKEN_USAGE[\"total\"] += int(usage.get(\"total_tokens\", 0) or (_TOKEN_USAGE[\"prompt\"] + _TOKEN_USAGE[\"completion\"]))\n",
    "\n",
    "def reset_token_usage():\n",
    "    \"\"\"Reset token usage counters.\"\"\"\n",
    "    _TOKEN_USAGE[\"prompt\"] = 0\n",
    "    _TOKEN_USAGE[\"completion\"] = 0\n",
    "    _TOKEN_USAGE[\"total\"] = 0\n",
    "\n",
    "print(\"‚úÖ Token tracking initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b1352",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Load Pricing Configuration\n",
    "\n",
    "Load token pricing from configuration file to calculate costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8bf653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pricing configuration loaded: 0 deployment(s) configured\n"
     ]
    }
   ],
   "source": [
    "def _load_pricing_config() -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Load pricing configuration from azure_openai_pricing.json.\"\"\"\n",
    "    try:\n",
    "        pricing_file = os.path.join(os.path.dirname(os.path.abspath('')), \"azure_openai_pricing.json\")\n",
    "        if os.path.exists(pricing_file):\n",
    "            with open(pricing_file, \"r\") as f:\n",
    "                return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load pricing config: {e}\")\n",
    "    return {}\n",
    "\n",
    "pricing_config = _load_pricing_config()\n",
    "print(f\"‚úÖ Pricing configuration loaded: {len(pricing_config)} deployment(s) configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc1cd1",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Define Sample Queries\n",
    "\n",
    "Let's define some example natural language queries to demonstrate the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd22c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sample Queries:\n",
      "  1. How many customers do I have?\n",
      "  2. Show me the top 5 loans by outstanding balance\n",
      "  3. What is the total collateral value across all loans?\n",
      "  4. List all companies in the Technology sector\n",
      "  5. Which region has the most loan applications?\n"
     ]
    }
   ],
   "source": [
    "# Sample queries for demonstration\n",
    "SAMPLE_QUERIES = [\n",
    "    \"How many customers do I have?\",\n",
    "    \"Show me the top 5 loans by outstanding balance\",\n",
    "    \"What is the total collateral value across all loans?\",\n",
    "    \"List all companies in the Technology sector\",\n",
    "    \"Which region has the most loan applications?\"\n",
    "]\n",
    "\n",
    "print(\"üìã Sample Queries:\")\n",
    "for i, query in enumerate(SAMPLE_QUERIES, 1):\n",
    "    print(f\"  {i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375ec29",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Intent Extraction Function\n",
    "\n",
    "This function uses AI to extract the intent and entities from a natural language question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e43936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Intent extraction function ready!\n"
     ]
    }
   ],
   "source": [
    "def extract_intent(query: str) -> str:\n",
    "    \"\"\"Extract intent and entities from natural language query.\"\"\"\n",
    "    \n",
    "    intent_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an AI assistant that extracts the intent and entities from natural language database queries.\n",
    "        \n",
    "Analyze the user's question and provide:\n",
    "1. The main intent (e.g., count, list, aggregate, filter)\n",
    "2. Key entities mentioned (tables, columns, metrics)\n",
    "3. Any filters or conditions\n",
    "4. Desired aggregations or groupings\n",
    "\n",
    "Return your analysis in JSON format with keys: intent, entity, metrics, filters, group_by.\"\"\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    if llm:\n",
    "        chain = intent_prompt | llm\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result.content\n",
    "    else:\n",
    "        # Direct API call for reasoning models\n",
    "        import requests\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": API_KEY,\n",
    "        }\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": intent_prompt.messages[0].prompt.template},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        data = {\"messages\": messages, \"max_tokens\": 2000}\n",
    "        \n",
    "        url = f\"{ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        \n",
    "        # Track usage\n",
    "        if \"usage\" in result:\n",
    "            _accumulate_usage(result[\"usage\"])\n",
    "        \n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(\"‚úÖ Intent extraction function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa018711",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Demo - Extract Intent from a Query\n",
    "\n",
    "Let's see the intent extraction in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312bd200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üîç DEMO: INTENT EXTRACTION\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "üìù Query: How many customers do I have?\n",
      "\n",
      "üß† EXTRACTED INTENT & ENTITIES:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "{\n",
      "  \"intent\": \"count\",\n",
      "  \"entity\": [\"customers\"],\n",
      "  \"metrics\": [\"count\"],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": []\n",
      "}\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚è±Ô∏è Time taken: 1.29 seconds\n",
      "üìä Tokens used: 0 (prompt: 0, completion: 0)\n",
      "üß† EXTRACTED INTENT & ENTITIES:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "{\n",
      "  \"intent\": \"count\",\n",
      "  \"entity\": [\"customers\"],\n",
      "  \"metrics\": [\"count\"],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": []\n",
      "}\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚è±Ô∏è Time taken: 1.29 seconds\n",
      "üìä Tokens used: 0 (prompt: 0, completion: 0)\n"
     ]
    }
   ],
   "source": [
    "# Choose a sample query\n",
    "demo_query = SAMPLE_QUERIES[0]  # \"How many customers do I have?\"\n",
    "\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"üîç DEMO: INTENT EXTRACTION\")\n",
    "print(\"‚ïê\" * 60)\n",
    "print(f\"\\nüìù Query: {demo_query}\\n\")\n",
    "\n",
    "# Reset token usage for this demo\n",
    "reset_token_usage()\n",
    "\n",
    "# Extract intent\n",
    "start_time = time.time()\n",
    "intent_result = extract_intent(demo_query)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(\"üß† EXTRACTED INTENT & ENTITIES:\")\n",
    "print(\"‚îÄ\" * 60)\n",
    "print(intent_result)\n",
    "print(\"‚îÄ\" * 60)\n",
    "print(f\"\\n‚è±Ô∏è Time taken: {elapsed:.2f} seconds\")\n",
    "print(f\"üìä Tokens used: {_TOKEN_USAGE['total']} (prompt: {_TOKEN_USAGE['prompt']}, completion: {_TOKEN_USAGE['completion']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f99027",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Import Schema Reader\n",
    "\n",
    "The schema reader helps the AI understand the database structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5328dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema reader imported successfully!\n",
      "\n",
      "üìä Schema loaded: 4777 characters\n",
      "\n",
      "Preview (first 500 chars):\n",
      "DATABASE: CONTOSO-FI (Azure SQL)\n",
      "GUIDELINES\n",
      "- Prefer dbo.vw_LoanPortfolio for simple portfolio-style questions.\n",
      "- For hard/complex questions, use the base tables (Loan, Company, Collateral, Covenant, PaymentSchedule, etc.) and generate SQL with multiple joins, subqueries, CTEs, or advanced logic as needed.\n",
      "- Use appropriate GROUP BY for aggregates; weight interest rate averages by PrincipalAmount if needed.\n",
      "- Do not emit USE or GO; return a single executable SELECT statement.\n",
      "\n",
      "VIEW\n",
      "- dbo.vw_Loan...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from schema_reader import get_sql_database_schema_context\n",
    "    print(\"‚úÖ Schema reader imported successfully!\")\n",
    "    \n",
    "    # Get a sample of the schema\n",
    "    schema_context = get_sql_database_schema_context()\n",
    "    print(f\"\\nüìä Schema loaded: {len(schema_context)} characters\")\n",
    "    print(f\"\\nPreview (first 500 chars):\\n{schema_context[:500]}...\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import schema_reader: {e}\")\n",
    "    print(\"Note: This is expected if running outside the main directory\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error loading schema: {e}\")\n",
    "    print(\"The pipeline will continue in generic mode without schema context\")\n",
    "    schema_context = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcbe27",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: SQL Generation Function\n",
    "\n",
    "This function generates T-SQL based on the intent and database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d674aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SQL generation function ready!\n"
     ]
    }
   ],
   "source": [
    "def generate_sql(intent: str, schema_context: str = \"\") -> str:\n",
    "    \"\"\"Generate SQL query based on extracted intent and schema.\"\"\"\n",
    "    \n",
    "    sql_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"You are an expert SQL query generator for Azure SQL Database.\n",
    "\n",
    "Given the user's intent and the database schema, generate a valid T-SQL query.\n",
    "\n",
    "Database Schema:\n",
    "{schema_context or 'Schema not provided - use generic table names'}\n",
    "\n",
    "Requirements:\n",
    "- Generate clean, efficient T-SQL\n",
    "- Use proper JOINs when needed\n",
    "- Include appropriate WHERE clauses for filters\n",
    "- Use meaningful column aliases\n",
    "- Return ONLY the SQL query, no explanations\n",
    "\"\"\"),\n",
    "        (\"user\", \"Intent: {intent}\\n\\nGenerate the SQL query:\")\n",
    "    ])\n",
    "    \n",
    "    if llm:\n",
    "        chain = sql_prompt | llm\n",
    "        result = chain.invoke({\"intent\": intent})\n",
    "        return result.content\n",
    "    else:\n",
    "        # Direct API call for reasoning models\n",
    "        import requests\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": API_KEY,\n",
    "        }\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sql_prompt.messages[0].prompt.template.format(schema_context=schema_context or 'Schema not provided')},\n",
    "            {\"role\": \"user\", \"content\": f\"Intent: {intent}\\n\\nGenerate the SQL query:\"}\n",
    "        ]\n",
    "        data = {\"messages\": messages, \"max_tokens\": 2000}\n",
    "        \n",
    "        url = f\"{ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        \n",
    "        # Track usage\n",
    "        if \"usage\" in result:\n",
    "            _accumulate_usage(result[\"usage\"])\n",
    "        \n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(\"‚úÖ SQL generation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf3f84",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 11: SQL Sanitization\n",
    "\n",
    "Extract clean SQL from the AI response (removes markdown formatting, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29a2c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SQL sanitization function ready!\n"
     ]
    }
   ],
   "source": [
    "def extract_and_sanitize_sql(raw_sql: str) -> str:\n",
    "    \"\"\"Extract and clean SQL from AI response.\"\"\"\n",
    "    # Remove markdown code blocks\n",
    "    sql = re.sub(r'^```(?:sql)?\\s*', '', raw_sql, flags=re.MULTILINE)\n",
    "    sql = re.sub(r'```\\s*$', '', sql, flags=re.MULTILINE)\n",
    "    \n",
    "    # Trim whitespace\n",
    "    sql = sql.strip()\n",
    "    \n",
    "    return sql\n",
    "\n",
    "print(\"‚úÖ SQL sanitization function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262f01f",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 12: Demo - Full Pipeline\n",
    "\n",
    "Now let's run the complete pipeline from natural language to SQL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c754f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline function ready!\n"
     ]
    }
   ],
   "source": [
    "def run_nl2sql_pipeline(query: str, execute: bool = False):\n",
    "    \"\"\"Run the complete NL2SQL pipeline.\"\"\"\n",
    "    \n",
    "    print(\"‚ïê\" * 70)\n",
    "    print(\"üöÄ COMPLETE NL2SQL PIPELINE\")\n",
    "    print(\"‚ïê\" * 70)\n",
    "    \n",
    "    # Reset token usage\n",
    "    reset_token_usage()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Display query\n",
    "    print(f\"\\nüìù NATURAL LANGUAGE QUERY\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    print(query)\n",
    "    \n",
    "    # Step 2: Extract intent\n",
    "    print(f\"\\n\\nüß† STEP 1: EXTRACT INTENT & ENTITIES\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    intent = extract_intent(query)\n",
    "    print(intent)\n",
    "    \n",
    "    # Step 3: Get schema (if available)\n",
    "    print(f\"\\n\\nüìä STEP 2: LOAD DATABASE SCHEMA\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    try:\n",
    "        schema = get_sql_database_schema_context()\n",
    "        print(f\"‚úÖ Schema loaded ({len(schema)} characters)\")\n",
    "    except Exception as e:\n",
    "        schema = \"\"\n",
    "        print(f\"‚ö†Ô∏è Schema not available (using generic mode): {e}\")\n",
    "    \n",
    "    # Step 4: Generate SQL\n",
    "    print(f\"\\n\\n‚ö° STEP 3: GENERATE SQL QUERY\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    raw_sql = generate_sql(intent, schema)\n",
    "    print(raw_sql)\n",
    "    \n",
    "    # Step 5: Sanitize SQL\n",
    "    print(f\"\\n\\nüîç STEP 4: SANITIZE SQL\")\n",
    "    print(\"‚îÄ\" * 70)\n",
    "    clean_sql = extract_and_sanitize_sql(raw_sql)\n",
    "    print(clean_sql)\n",
    "    \n",
    "    # Step 6: Execute (if requested)\n",
    "    if execute:\n",
    "        print(f\"\\n\\nüéØ STEP 5: EXECUTE QUERY\")\n",
    "        print(\"‚îÄ\" * 70)\n",
    "        try:\n",
    "            from sql_executor import execute_sql_query\n",
    "            results = execute_sql_query(clean_sql)\n",
    "            print(f\"‚úÖ Query executed successfully! Returned {len(results)} row(s)\")\n",
    "            if results:\n",
    "                print(\"\\nResults:\")\n",
    "                for i, row in enumerate(results[:5], 1):  # Show first 5 rows\n",
    "                    print(f\"  {i}. {row}\")\n",
    "                if len(results) > 5:\n",
    "                    print(f\"  ... and {len(results) - 5} more row(s)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Execution error: {e}\")\n",
    "    else:\n",
    "        print(f\"\\n\\n‚è≠Ô∏è STEP 5: EXECUTION SKIPPED\")\n",
    "        print(\"‚îÄ\" * 70)\n",
    "        print(\"Set execute=True to run the query against the database\")\n",
    "    \n",
    "    # Summary\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n\\nüìà PIPELINE SUMMARY\")\n",
    "    print(\"‚ïê\" * 70)\n",
    "    print(f\"‚è±Ô∏è Total time: {elapsed:.2f} seconds\")\n",
    "    print(f\"üìä Total tokens: {_TOKEN_USAGE['total']} (prompt: {_TOKEN_USAGE['prompt']}, completion: {_TOKEN_USAGE['completion']})\")\n",
    "    \n",
    "    # Calculate cost if pricing available\n",
    "    if pricing_config and DEPLOYMENT_NAME:\n",
    "        dep_key = DEPLOYMENT_NAME.lower()\n",
    "        if dep_key in pricing_config:\n",
    "            prices = pricing_config[dep_key]\n",
    "            input_cost = (_TOKEN_USAGE['prompt'] / 1000.0) * prices.get('input_per_1k', 0)\n",
    "            output_cost = (_TOKEN_USAGE['completion'] / 1000.0) * prices.get('output_per_1k', 0)\n",
    "            total_cost = input_cost + output_cost\n",
    "            print(f\"üí∞ Estimated cost: ${total_cost:.6f} USD\")\n",
    "    \n",
    "    print(\"‚ïê\" * 70)\n",
    "\n",
    "print(\"‚úÖ Pipeline function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd7ec6",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 13: Run a Demo Query\n",
    "\n",
    "Let's test the pipeline with our sample query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d7ebb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üöÄ COMPLETE NL2SQL PIPELINE\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "üìù NATURAL LANGUAGE QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "How many customers do I have?\n",
      "\n",
      "\n",
      "üß† STEP 1: EXTRACT INTENT & ENTITIES\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "{\n",
      "  \"intent\": \"count\",\n",
      "  \"entity\": \"customers\",\n",
      "  \"metrics\": [\"customer_count\"],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": []\n",
      "}\n",
      "\n",
      "\n",
      "üìä STEP 2: LOAD DATABASE SCHEMA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Schema loaded (4777 characters)\n",
      "\n",
      "\n",
      "‚ö° STEP 3: GENERATE SQL QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "{\n",
      "  \"intent\": \"count\",\n",
      "  \"entity\": \"customers\",\n",
      "  \"metrics\": [\"customer_count\"],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": []\n",
      "}\n",
      "\n",
      "\n",
      "üìä STEP 2: LOAD DATABASE SCHEMA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Schema loaded (4777 characters)\n",
      "\n",
      "\n",
      "‚ö° STEP 3: GENERATE SQL QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT COUNT(*) AS customer_count\n",
      "FROM dbo.Company;\n",
      "\n",
      "\n",
      "üîç STEP 4: SANITIZE SQL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT COUNT(*) AS customer_count\n",
      "FROM dbo.Company;\n",
      "\n",
      "\n",
      "üéØ STEP 5: EXECUTE QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT COUNT(*) AS customer_count\n",
      "FROM dbo.Company;\n",
      "\n",
      "\n",
      "üîç STEP 4: SANITIZE SQL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT COUNT(*) AS customer_count\n",
      "FROM dbo.Company;\n",
      "\n",
      "\n",
      "üéØ STEP 5: EXECUTE QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Query executed successfully! Returned 1 row(s)\n",
      "\n",
      "Results:\n",
      "  1. {'customer_count': 15}\n",
      "\n",
      "\n",
      "üìà PIPELINE SUMMARY\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚è±Ô∏è Total time: 6.77 seconds\n",
      "üìä Total tokens: 0 (prompt: 0, completion: 0)\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚úÖ Query executed successfully! Returned 1 row(s)\n",
      "\n",
      "Results:\n",
      "  1. {'customer_count': 15}\n",
      "\n",
      "\n",
      "üìà PIPELINE SUMMARY\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚è±Ô∏è Total time: 6.77 seconds\n",
      "üìä Total tokens: 0 (prompt: 0, completion: 0)\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline with the first sample query\n",
    "run_nl2sql_pipeline(SAMPLE_QUERIES[0], execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde2113",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 14: Try Your Own Query\n",
    "\n",
    "Now you can test with your own natural language question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc2982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "üöÄ COMPLETE NL2SQL PIPELINE\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "üìù NATURAL LANGUAGE QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Show me the top 5 loans by outstanding balance\n",
      "\n",
      "\n",
      "üß† STEP 1: EXTRACT INTENT & ENTITIES\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "{\n",
      "  \"intent\": \"list\",\n",
      "  \"entity\": [\"loans\", \"outstanding balance\"],\n",
      "  \"metrics\": [\"outstanding balance\"],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": [],\n",
      "  \"sort\": {\n",
      "    \"by\": \"outstanding balance\",\n",
      "    \"order\": \"desc\",\n",
      "    \"limit\": 5\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "üìä STEP 2: LOAD DATABASE SCHEMA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Schema loaded (4777 characters)\n",
      "\n",
      "\n",
      "‚ö° STEP 3: GENERATE SQL QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "{\n",
      "  \"intent\": \"list\",\n",
      "  \"entity\": [\"loans\", \"outstanding balance\"],\n",
      "  \"metrics\": [\"outstanding balance\"],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": [],\n",
      "  \"sort\": {\n",
      "    \"by\": \"outstanding balance\",\n",
      "    \"order\": \"desc\",\n",
      "    \"limit\": 5\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "üìä STEP 2: LOAD DATABASE SCHEMA\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Schema loaded (4777 characters)\n",
      "\n",
      "\n",
      "‚ö° STEP 3: GENERATE SQL QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT\n",
      "    LoanId,\n",
      "    LoanNumber,\n",
      "    CompanyName,\n",
      "    PrincipalAmount AS OutstandingBalance,\n",
      "    CurrencyCode,\n",
      "    OriginationDate,\n",
      "    MaturityDate,\n",
      "    Status\n",
      "FROM dbo.vw_LoanPortfolio\n",
      "WHERE Status = 'Active'\n",
      "ORDER BY PrincipalAmount DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 5 ROWS ONLY;\n",
      "\n",
      "\n",
      "üîç STEP 4: SANITIZE SQL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT\n",
      "    LoanId,\n",
      "    LoanNumber,\n",
      "    CompanyName,\n",
      "    PrincipalAmount AS OutstandingBalance,\n",
      "    CurrencyCode,\n",
      "    OriginationDate,\n",
      "    MaturityDate,\n",
      "    Status\n",
      "FROM dbo.vw_LoanPortfolio\n",
      "WHERE Status = 'Active'\n",
      "ORDER BY PrincipalAmount DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 5 ROWS ONLY;\n",
      "\n",
      "\n",
      "üéØ STEP 5: EXECUTE QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT\n",
      "    LoanId,\n",
      "    LoanNumber,\n",
      "    CompanyName,\n",
      "    PrincipalAmount AS OutstandingBalance,\n",
      "    CurrencyCode,\n",
      "    OriginationDate,\n",
      "    MaturityDate,\n",
      "    Status\n",
      "FROM dbo.vw_LoanPortfolio\n",
      "WHERE Status = 'Active'\n",
      "ORDER BY PrincipalAmount DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 5 ROWS ONLY;\n",
      "\n",
      "\n",
      "üîç STEP 4: SANITIZE SQL\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "SELECT\n",
      "    LoanId,\n",
      "    LoanNumber,\n",
      "    CompanyName,\n",
      "    PrincipalAmount AS OutstandingBalance,\n",
      "    CurrencyCode,\n",
      "    OriginationDate,\n",
      "    MaturityDate,\n",
      "    Status\n",
      "FROM dbo.vw_LoanPortfolio\n",
      "WHERE Status = 'Active'\n",
      "ORDER BY PrincipalAmount DESC\n",
      "OFFSET 0 ROWS FETCH NEXT 5 ROWS ONLY;\n",
      "\n",
      "\n",
      "üéØ STEP 5: EXECUTE QUERY\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "‚úÖ Query executed successfully! Returned 5 row(s)\n",
      "\n",
      "Results:\n",
      "  1. {'LoanId': 2, 'LoanNumber': 'US-00001', 'CompanyName': 'Blue Ridge Energy Corp', 'OutstandingBalance': Decimal('25000000.00'), 'CurrencyCode': 'USD', 'OriginationDate': datetime.date(2022, 8, 27), 'MaturityDate': datetime.date(2027, 8, 27), 'Status': 'Active'}\n",
      "  2. {'LoanId': 3, 'LoanNumber': 'US-00002', 'CompanyName': 'Toronto Health Devices', 'OutstandingBalance': Decimal('25000000.00'), 'CurrencyCode': 'USD', 'OriginationDate': datetime.date(2022, 8, 27), 'MaturityDate': datetime.date(2027, 8, 27), 'Status': 'Active'}\n",
      "  3. {'LoanId': 8, 'LoanNumber': 'AS-00001', 'CompanyName': 'Osaka Precision K.K.', 'OutstandingBalance': Decimal('22000000.00'), 'CurrencyCode': 'JPY', 'OriginationDate': datetime.date(2024, 8, 27), 'MaturityDate': datetime.date(2029, 8, 27), 'Status': 'Active'}\n",
      "  4. {'LoanId': 9, 'LoanNumber': 'AS-00002', 'CompanyName': 'Shanghai GreenChem Co', 'OutstandingBalance': Decimal('22000000.00'), 'CurrencyCode': 'CNY', 'OriginationDate': datetime.date(2024, 8, 27), 'MaturityDate': datetime.date(2029, 8, 27), 'Status': 'Active'}\n",
      "  5. {'LoanId': 10, 'LoanNumber': 'AS-00003', 'CompanyName': 'Mumbai InfraTech Ltd', 'OutstandingBalance': Decimal('22000000.00'), 'CurrencyCode': 'INR', 'OriginationDate': datetime.date(2024, 8, 27), 'MaturityDate': datetime.date(2029, 8, 27), 'Status': 'Active'}\n",
      "\n",
      "\n",
      "üìà PIPELINE SUMMARY\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚è±Ô∏è Total time: 4.34 seconds\n",
      "üìä Total tokens: 0 (prompt: 0, completion: 0)\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚úÖ Query executed successfully! Returned 5 row(s)\n",
      "\n",
      "Results:\n",
      "  1. {'LoanId': 2, 'LoanNumber': 'US-00001', 'CompanyName': 'Blue Ridge Energy Corp', 'OutstandingBalance': Decimal('25000000.00'), 'CurrencyCode': 'USD', 'OriginationDate': datetime.date(2022, 8, 27), 'MaturityDate': datetime.date(2027, 8, 27), 'Status': 'Active'}\n",
      "  2. {'LoanId': 3, 'LoanNumber': 'US-00002', 'CompanyName': 'Toronto Health Devices', 'OutstandingBalance': Decimal('25000000.00'), 'CurrencyCode': 'USD', 'OriginationDate': datetime.date(2022, 8, 27), 'MaturityDate': datetime.date(2027, 8, 27), 'Status': 'Active'}\n",
      "  3. {'LoanId': 8, 'LoanNumber': 'AS-00001', 'CompanyName': 'Osaka Precision K.K.', 'OutstandingBalance': Decimal('22000000.00'), 'CurrencyCode': 'JPY', 'OriginationDate': datetime.date(2024, 8, 27), 'MaturityDate': datetime.date(2029, 8, 27), 'Status': 'Active'}\n",
      "  4. {'LoanId': 9, 'LoanNumber': 'AS-00002', 'CompanyName': 'Shanghai GreenChem Co', 'OutstandingBalance': Decimal('22000000.00'), 'CurrencyCode': 'CNY', 'OriginationDate': datetime.date(2024, 8, 27), 'MaturityDate': datetime.date(2029, 8, 27), 'Status': 'Active'}\n",
      "  5. {'LoanId': 10, 'LoanNumber': 'AS-00003', 'CompanyName': 'Mumbai InfraTech Ltd', 'OutstandingBalance': Decimal('22000000.00'), 'CurrencyCode': 'INR', 'OriginationDate': datetime.date(2024, 8, 27), 'MaturityDate': datetime.date(2029, 8, 27), 'Status': 'Active'}\n",
      "\n",
      "\n",
      "üìà PIPELINE SUMMARY\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "‚è±Ô∏è Total time: 4.34 seconds\n",
      "üìä Total tokens: 0 (prompt: 0, completion: 0)\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and modify to try your own query:\n",
    "# custom_query = \"What are the total loan amounts by region?\"\n",
    "# run_nl2sql_pipeline(custom_query, execute=False)\n",
    "\n",
    "# Or try another sample:\n",
    "run_nl2sql_pipeline(SAMPLE_QUERIES[1], execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bc067",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Demo Complete!\n",
    "\n",
    "### What We Demonstrated:\n",
    "1. ‚úÖ Loading and configuring Azure OpenAI\n",
    "2. ‚úÖ Extracting intent from natural language\n",
    "3. ‚úÖ Loading database schema context\n",
    "4. ‚úÖ Generating T-SQL queries using AI\n",
    "5. ‚úÖ Sanitizing and validating SQL\n",
    "6. ‚úÖ Tracking token usage and costs\n",
    "\n",
    "### Key Benefits:\n",
    "- üöÄ **Speed**: Generate complex queries in seconds\n",
    "- üí° **Accessibility**: No SQL knowledge required\n",
    "- üéØ **Accuracy**: Schema-aware generation\n",
    "- üí∞ **Cost Tracking**: Monitor API usage and costs\n",
    "- üîí **Safety**: SQL sanitization and validation\n",
    "\n",
    "### Next Steps:\n",
    "- Run the complete pipeline with `nl2sql_main.py`\n",
    "- Integrate with your own applications\n",
    "- Customize prompts for your specific domain\n",
    "- Add more sophisticated error handling\n",
    "- Implement query result caching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

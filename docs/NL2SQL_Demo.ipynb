{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373db31a",
   "metadata": {},
   "source": [
    "# NL→SQL Demo Notebook (Azure OpenAI + Azure SQL)\n",
    "\n",
    "This notebook demonstrates the NL→Intent→SQL pipeline step by step, aligned with the project's flowchart.\n",
    "Each step includes explanation cells for demo purposes (e.g., for a TERADATA partner presentation).\n",
    "\n",
    "Prereqs: ensure you have a valid .env configured for Azure OpenAI and Azure SQL (see README)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f9edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded. Project root: /Users/arturoquiroga/GITHUB/AQ-NEW-NL2SQL/docs\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports and environment bootstrap\n",
    "import os, re, sys\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "print('Environment loaded. Project root:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c865e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run & verbosity gate setup (placed early so checkpoints can call it)\n",
    "import time\n",
    "if 'RUN_START_TS' not in globals():\n",
    "    RUN_START_TS = time.time()  # capture start as early as possible\n",
    "\n",
    "# Toggle to reduce verbosity of intermediate checkpoint prints\n",
    "if 'SHOW_COSTS' not in globals():\n",
    "    SHOW_COSTS = True\n",
    "\n",
    "def maybe_print_checkpoint(header: str):\n",
    "    try:\n",
    "        if SHOW_COSTS:\n",
    "            print_usage_and_cost(DEPLOYMENT_NAME, header=header)\n",
    "    except NameError:\n",
    "        # Helpers not yet loaded; safe no-op\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ded38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Token tracking] Enabled global interceptors for REST and LangChain.\n"
     ]
    }
   ],
   "source": [
    "# Enable global token/cost tracking early in the notebook\n",
    "import os, json, re\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import types\n",
    "\n",
    "# Accumulator\n",
    "TOKEN_USAGE = globals().get(\"TOKEN_USAGE\", {\"prompt\": 0, \"completion\": 0, \"total\": 0})\n",
    "\n",
    "def accumulate_usage(usage: Optional[Dict[str, Any]]):\n",
    "    if not usage:\n",
    "        return\n",
    "    TOKEN_USAGE[\"prompt\"] += int(usage.get(\"prompt_tokens\", 0) or 0)\n",
    "    TOKEN_USAGE[\"completion\"] += int(usage.get(\"completion_tokens\", 0) or 0)\n",
    "    if usage.get(\"total_tokens\") is not None:\n",
    "        TOKEN_USAGE[\"total\"] += int(usage.get(\"total_tokens\") or 0)\n",
    "    else:\n",
    "        TOKEN_USAGE[\"total\"] = TOKEN_USAGE[\"prompt\"] + TOKEN_USAGE[\"completion\"]\n",
    "\n",
    "def extract_usage_from_rest(resp_json: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    return resp_json.get(\"usage\") if isinstance(resp_json, dict) else None\n",
    "\n",
    "def extract_usage_from_langchain(ai_msg: Any) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        meta = getattr(ai_msg, \"response_metadata\", None) or {}\n",
    "        tu = meta.get(\"token_usage\")\n",
    "        if isinstance(tu, dict):\n",
    "            return {\n",
    "                \"prompt_tokens\": tu.get(\"prompt_tokens\") or tu.get(\"input_tokens\") or 0,\n",
    "                \"completion_tokens\": tu.get(\"completion_tokens\") or tu.get(\"output_tokens\") or 0,\n",
    "                \"total_tokens\": tu.get(\"total_tokens\") or (tu.get(\"prompt_tokens\", 0) or 0) + (tu.get(\"completion_tokens\", 0) or 0),\n",
    "            }\n",
    "        um = getattr(ai_msg, \"usage_metadata\", None)\n",
    "        if isinstance(um, dict):\n",
    "            return {\n",
    "                \"prompt_tokens\": um.get(\"input_tokens\") or um.get(\"prompt_tokens\") or 0,\n",
    "                \"completion_tokens\": um.get(\"output_tokens\") or um.get(\"completion_tokens\") or 0,\n",
    "                \"total_tokens\": um.get(\"total_tokens\") or (um.get(\"input_tokens\", 0) or 0) + (um.get(\"output_tokens\", 0) or 0),\n",
    "            }\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def normalize_dep(name: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"_\", (name or \"\")).upper().strip(\"_\")\n",
    "\n",
    "def load_pricing() -> Dict[str, Dict[str, Any]]:\n",
    "    # search repo root for azure_openai_pricing.json\n",
    "    here = Path.cwd()\n",
    "    candidates = [here / \"azure_openai_pricing.json\", here.parent / \"azure_openai_pricing.json\"] if here.name == \"docs\" else [here / \"azure_openai_pricing.json\"]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                return json.loads(p.read_text())\n",
    "            except Exception:\n",
    "                return {}\n",
    "    return {}\n",
    "\n",
    "def get_target_currency() -> str:\n",
    "    cur = (os.getenv(\"AZURE_OPENAI_PRICE_CURRENCY\", \"USD\") or \"USD\").upper()\n",
    "    return cur if cur in (\"USD\", \"CAD\") else \"USD\"\n",
    "\n",
    "def convert_currency(amount: float, from_cur: str, to_cur: str) -> Optional[float]:\n",
    "    if from_cur == to_cur:\n",
    "        return amount\n",
    "    if from_cur == \"USD\" and to_cur == \"CAD\":\n",
    "        rate = os.getenv(\"AZURE_OPENAI_PRICE_USD_TO_CAD\")\n",
    "        return amount * float(rate) if rate else None\n",
    "    if from_cur == \"CAD\" and to_cur == \"USD\":\n",
    "        rate = os.getenv(\"AZURE_OPENAI_PRICE_CAD_TO_USD\")\n",
    "        return amount * float(rate) if rate else None\n",
    "    return None\n",
    "\n",
    "def get_pricing_for_deployment(dep_name: Optional[str]) -> Tuple[Optional[float], Optional[float], str, str]:\n",
    "    dep = dep_name or \"\"\n",
    "    dep_key = normalize_dep(dep)\n",
    "    target = get_target_currency()\n",
    "\n",
    "    # 1) Deployment-specific env\n",
    "    in_env = os.getenv(f\"AZURE_OPENAI_PRICE_{dep_key}_INPUT_PER_1K\")\n",
    "    out_env = os.getenv(f\"AZURE_OPENAI_PRICE_{dep_key}_OUTPUT_PER_1K\")\n",
    "    if in_env and out_env:\n",
    "        try:\n",
    "            return float(in_env), float(out_env), f\"env:{dep_key}\", target\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 2) Global env\n",
    "    in_glob = os.getenv(\"AZURE_OPENAI_PRICE_INPUT_PER_1K\")\n",
    "    out_glob = os.getenv(\"AZURE_OPENAI_PRICE_OUTPUT_PER_1K\")\n",
    "    if in_glob and out_glob:\n",
    "        try:\n",
    "            return float(in_glob), float(out_glob), \"env:global\", target\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 3) JSON file\n",
    "    pm = load_pricing()\n",
    "    entry = pm.get(dep.lower()) or pm.get(dep)\n",
    "    if isinstance(entry, dict):\n",
    "        # nested per-currency\n",
    "        cur_block = entry.get(target)\n",
    "        if isinstance(cur_block, dict) and \"input_per_1k\" in cur_block and \"output_per_1k\" in cur_block:\n",
    "            try:\n",
    "                return float(cur_block[\"input_per_1k\"]), float(cur_block[\"output_per_1k\"]), \"file:azure_openai_pricing.json\", target\n",
    "            except Exception:\n",
    "                pass\n",
    "        # flat (assumed USD)\n",
    "        if \"input_per_1k\" in entry and \"output_per_1k\" in entry:\n",
    "            try:\n",
    "                in_usd = float(entry[\"input_per_1k\"])\n",
    "                out_usd = float(entry[\"output_per_1k\"])\n",
    "                if target == \"USD\":\n",
    "                    return in_usd, out_usd, \"file:azure_openai_pricing.json\", \"USD\"\n",
    "                i = convert_currency(in_usd, \"USD\", target)\n",
    "                o = convert_currency(out_usd, \"USD\", target)\n",
    "                if i is not None and o is not None:\n",
    "                    return i, o, \"file:azure_openai_pricing.json (converted)\", target\n",
    "                return in_usd, out_usd, \"file:azure_openai_pricing.json (USD; no conversion)\", \"USD\"\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None, None, \"unset\", target\n",
    "\n",
    "def print_usage_and_cost(dep_name: Optional[str], header: Optional[str] = None):\n",
    "    in_p, out_p, src, cur = get_pricing_for_deployment(dep_name)\n",
    "    pt = TOKEN_USAGE[\"prompt\"]\n",
    "    ct = TOKEN_USAGE[\"completion\"]\n",
    "    tt = TOKEN_USAGE[\"total\"] or (pt + ct)\n",
    "    if header:\n",
    "        print(f\"\\n==== {header} ====\")\n",
    "    print(\"\\n==== TOKEN USAGE (cumulative) ====\")\n",
    "    print(f\"Input tokens: {pt}\")\n",
    "    print(f\"Completion tokens: {ct}\")\n",
    "    print(f\"Total tokens: {tt}\")\n",
    "    if in_p is not None and out_p is not None:\n",
    "        ic = (pt/1000.0) * in_p\n",
    "        oc = (ct/1000.0) * out_p\n",
    "        tc = ic + oc\n",
    "        print(\"==== COST ESTIMATE ====\")\n",
    "        print(f\"Currency: {cur}\")\n",
    "        print(f\"Per-1K prices (input={in_p}, output={out_p}) [source={src}]\")\n",
    "        print(f\"Estimated cost: {tc:.6f}  [input={ic:.6f}, output={oc:.6f}]\")\n",
    "    else:\n",
    "        print(\"[INFO] Pricing not configured. Set AZURE_OPENAI_PRICE_* env vars or azure_openai_pricing.json.\")\n",
    "\n",
    "# Monkey-patch requests.post to auto-capture usage for REST calls\n",
    "try:\n",
    "    import requests\n",
    "    if not hasattr(requests, \"_orig_post_for_tokens\"):\n",
    "        requests._orig_post_for_tokens = requests.post\n",
    "        def _post_wrap(*args, **kwargs):\n",
    "            resp = requests._orig_post_for_tokens(*args, **kwargs)\n",
    "            try:\n",
    "                url = args[0] if args else kwargs.get(\"url\", \"\")\n",
    "                if isinstance(url, str) and \"/chat/completions\" in url:\n",
    "                    # non-blocking attempt to capture usage\n",
    "                    data = resp.json()\n",
    "                    u = extract_usage_from_rest(data)\n",
    "                    accumulate_usage(u)\n",
    "            except Exception:\n",
    "                pass\n",
    "            return resp\n",
    "        requests.post = _post_wrap\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Patch LangChain llm.invoke (if present) to capture usage automatically\n",
    "try:\n",
    "    if 'llm' in globals() and llm is not None and not hasattr(llm, \"_invoke_patched_for_tokens\"):\n",
    "        _orig_invoke = llm.invoke\n",
    "        def _invoke_wrap(*args, **kwargs):\n",
    "            res = _orig_invoke(*args, **kwargs)\n",
    "            try:\n",
    "                accumulate_usage(extract_usage_from_langchain(res))\n",
    "            except Exception:\n",
    "                pass\n",
    "            return res\n",
    "        llm.invoke = types.MethodType(_invoke_wrap, llm)\n",
    "        llm._invoke_patched_for_tokens = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"[Token tracking] Enabled global interceptors for REST and LangChain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd547a",
   "metadata": {},
   "source": [
    "## Demo settings (global)\n",
    "\n",
    "- Control printing and execution across the notebook from one place.\n",
    "- You can still override the query text in runner cells if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74443d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo settings -> SHOW_INTENT: True | SHOW_REASONING: True | NO_EXEC: False | REFRESH_SCHEMA: False\n"
     ]
    }
   ],
   "source": [
    "# Demo settings (global)\n",
    "# These control printing and execution across the notebook.\n",
    "SHOW_INTENT = True\n",
    "SHOW_REASONING = True\n",
    "NO_EXEC = False\n",
    "REFRESH_SCHEMA = False\n",
    "\n",
    "# Default query used by runner cells unless overridden\n",
    "default_test_query = 'Weighted average interest rate by region'\n",
    "print('Demo settings -> SHOW_INTENT:', SHOW_INTENT, '| SHOW_REASONING:', SHOW_REASONING, '| NO_EXEC:', NO_EXEC, '| REFRESH_SCHEMA:', REFRESH_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fda821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After this step, print cumulative token usage/cost\n",
    "maybe_print_checkpoint(\"After environment/bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c570b3",
   "metadata": {},
   "source": [
    "### Display Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5ed898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display helpers (ANSI colors for sectioned output)\n",
    "RESET = \"\\033[0m\"\n",
    "YELLOW = \"\\033[33m\"           # intent\n",
    "LIGHT_BLUE = \"\\033[96m\"       # reasoning (bright cyan)\n",
    "WHITE = \"\\033[97m\"            # raw sql\n",
    "GRAY = \"\\033[90m\"             # legacy dark gray (not used for sanitized anymore)\n",
    "LIGHT_GRAY = \"\\033[38;5;250m\" # sanitized sql (lighter and more readable)\n",
    "GOLD = \"\\033[38;5;220m\"      # results (approx gold)\n",
    "\n",
    "def colorize(text: str, color: str) -> str:\n",
    "    return f\"{color}{text}{RESET}\"\n",
    "\n",
    "def print_colored_block(label: str, content: str, color: str, sep: str = \"\\n\") -> None:\n",
    "    block = f\"{label}{sep}{content}\" if content is not None else label\n",
    "    print(colorize(block, color))\n",
    "    print()  # extra blank line for spacing between output blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0471bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After schema preview step\n",
    "maybe_print_checkpoint(\"After schema preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b81a0",
   "metadata": {},
   "source": [
    "## Azure OpenAI setup and model routing\n",
    "We detect reasoning-style deployments (o-series/GPT-5) and use direct REST Chat Completions without unsupported params.\n",
    "For other models, we use the LangChain AzureChatOpenAI wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a9a82d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning-style deployment: True | Deployment: gpt-5\n",
      "LangChain LLM initialized: False\n"
     ]
    }
   ],
   "source": [
    "# 2) Azure OpenAI configuration & helpers\n",
    "import json, requests\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "DEPLOYMENT_NAME = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION', '2025-04-01-preview')\n",
    "\n",
    "def _is_reasoning_like_model(deployment_name: str | None) -> bool:\n",
    "    name = (deployment_name or '').lower()\n",
    "    return name.startswith('o') or name.startswith('gpt-5')\n",
    "\n",
    "USING_REASONING = _is_reasoning_like_model(DEPLOYMENT_NAME)\n",
    "print('Reasoning-style deployment:', USING_REASONING, '| Deployment:', DEPLOYMENT_NAME)\n",
    "\n",
    "def _azure_chat_completions(messages: List[dict], max_completion_tokens: int | None = None) -> str:\n",
    "    url = f\"{ENDPOINT.rstrip('/')}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "    payload: Dict[str, Any] = {'messages': messages}\n",
    "    if max_completion_tokens is not None:\n",
    "        payload['max_completion_tokens'] = max_completion_tokens\n",
    "    headers = {'api-key': API_KEY or '', 'Content-Type': 'application/json'}\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data['choices'][0]['message']['content']\n",
    "\n",
    "def _make_llm():\n",
    "    if USING_REASONING:\n",
    "        return None\n",
    "    return AzureChatOpenAI(\n",
    "        openai_api_key=API_KEY,\n",
    "        azure_endpoint=ENDPOINT,\n",
    "        deployment_name=DEPLOYMENT_NAME,\n",
    "        api_version=API_VERSION,\n",
    "        max_tokens=8192,\n",
    "    )\n",
    "\n",
    "llm = _make_llm()\n",
    "print('LangChain LLM initialized:', llm is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dcda3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== After intent & entities ====\n",
      "\n",
      "==== TOKEN USAGE (cumulative) ====\n",
      "Input tokens: 0\n",
      "Completion tokens: 0\n",
      "Total tokens: 0\n",
      "==== COST ESTIMATE ====\n",
      "Currency: USD\n",
      "Per-1K prices (input=0.00125, output=0.01) [source=file:azure_openai_pricing.json]\n",
      "Estimated cost: 0.000000  [input=0.000000, output=0.000000]\n"
     ]
    }
   ],
   "source": [
    "# After intent extraction\n",
    "maybe_print_checkpoint(\"After intent & entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4eef46",
   "metadata": {},
   "source": [
    "## Prompts & function: Parse NL into intent/entities\n",
    "We keep prompt strings inline to mirror the main script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1374ca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_nl_query ready.\n"
     ]
    }
   ],
   "source": [
    "# 3) Prompts and parsing function\n",
    "INTENT_PROMPT_TEXT = (\n",
    "    \"You are an expert in translating natural language to database queries.\\n\"\n",
    "    \"Extract the intent and entities from the following user input:\\n\"\n",
    "    \"{input}\"\n",
    ")\n",
    "SQL_PROMPT_TEXT = (\n",
    "    \"You are an expert in SQL and Azure SQL Database. Given the following database schema and the intent/entities,\\n\"\n",
    "    \"generate a valid T-SQL query for querying the database.\\n\\n\"\n",
    "    \"IMPORTANT:\\n\"\n",
    "    \"- Do NOT use USE statements (USE [database] is not supported in Azure SQL Database)\\n\"\n",
    "    \"- Generate only the SELECT query without USE or GO statements\\n\"\n",
    "    \"- Return only executable T-SQL code without markdown formatting\\n\"\n",
    "    \"- The database connection is already established to the correct database\\n\\n\"\n",
    "    \"Schema:\\n\"\n",
    "    \"{schema}\\n\"\n",
    "    \"Intent and Entities:\\n\"\n",
    "    \"{intent_entities}\\n\\n\"\n",
    "    \"Generate a T-SQL query that can be executed directly:\\n\"\n",
    ")\n",
    "REASONING_PROMPT_TEXT = (\n",
    "    \"Before writing SQL, produce a short, high-level reasoning summary for how you will construct the query,\\n\"\n",
    "    \"based on the schema and the intent/entities.\\n\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"- Do NOT include any SQL code.\\n\"\n",
    "    \"- Keep it concise (<= 150 words) and actionable.\\n\"\n",
    "    \"- Use simple bullets covering: Entities mapping, Tables/Joins, Aggregations (if any), Filters, Order/Limit, Assumptions.\\n\\n\"\n",
    "    \"Schema:\\n\"\n",
    "    \"{schema}\\n\"\n",
    "    \"Intent and Entities:\\n\"\n",
    "    \"{intent_entities}\\n\\n\"\n",
    "    \"Provide the reasoning summary now:\\n\"\n",
    ")\n",
    "\n",
    "intent_prompt = ChatPromptTemplate.from_template(INTENT_PROMPT_TEXT)\n",
    "sql_prompt = ChatPromptTemplate.from_template(SQL_PROMPT_TEXT)\n",
    "reasoning_prompt = ChatPromptTemplate.from_template(REASONING_PROMPT_TEXT)\n",
    "\n",
    "def parse_nl_query(user_input: str) -> str:\n",
    "    if USING_REASONING:\n",
    "        prompt_text = INTENT_PROMPT_TEXT.format(input=user_input)\n",
    "        messages = [{ 'role': 'user', 'content': prompt_text.strip() }]\n",
    "        return _azure_chat_completions(messages, max_completion_tokens=8192)\n",
    "    chain = intent_prompt | llm\n",
    "    res = chain.invoke({'input': user_input})\n",
    "    return res.content\n",
    "\n",
    "print('parse_nl_query ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfecc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== After reasoning summary ====\n",
      "\n",
      "==== TOKEN USAGE (cumulative) ====\n",
      "Input tokens: 0\n",
      "Completion tokens: 0\n",
      "Total tokens: 0\n",
      "==== COST ESTIMATE ====\n",
      "Currency: USD\n",
      "Per-1K prices (input=0.00125, output=0.01) [source=file:azure_openai_pricing.json]\n",
      "Estimated cost: 0.000000  [input=0.000000, output=0.000000]\n"
     ]
    }
   ],
   "source": [
    "# After reasoning summary (if executed)\n",
    "maybe_print_checkpoint(\"After reasoning summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d62ec2",
   "metadata": {},
   "source": [
    "## Schema context (with optional refresh)\n",
    "We use the local cache-backed context from `schema_reader.get_sql_database_schema_context`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3c29e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE: CONTOSO-FI (Azure SQL)\n"
     ]
    }
   ],
   "source": [
    "# 4) Schema context helpers\n",
    "\n",
    "def _safe_import_schema_reader():\n",
    "    # add project root to path for relative imports while running from docs/\n",
    "    repo_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == 'docs' else os.getcwd()\n",
    "    if repo_root not in sys.path:\n",
    "        sys.path.insert(0, repo_root)\n",
    "    try:\n",
    "        from schema_reader import get_sql_database_schema_context, refresh_schema_cache  # type: ignore\n",
    "        return get_sql_database_schema_context, refresh_schema_cache\n",
    "    except Exception as e:\n",
    "        raise ImportError('Unable to import schema helpers from schema_reader.py') from e\n",
    "\n",
    "get_schema_ctx, refresh_cache = _safe_import_schema_reader()\n",
    "if REFRESH_SCHEMA:\n",
    "    try:\n",
    "        path = refresh_cache()\n",
    "        print('[INFO] Schema cache refreshed at', path)\n",
    "    except Exception as e:\n",
    "        print('[WARN] Schema refresh failed:', e)\n",
    "\n",
    "schema_preview = get_schema_ctx()\n",
    "print(schema_preview.split('\\n')[0])  # first line only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce598404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== After SQL generation ====\n",
      "\n",
      "==== TOKEN USAGE (cumulative) ====\n",
      "Input tokens: 0\n",
      "Completion tokens: 0\n",
      "Total tokens: 0\n",
      "==== COST ESTIMATE ====\n",
      "Currency: USD\n",
      "Per-1K prices (input=0.00125, output=0.01) [source=file:azure_openai_pricing.json]\n",
      "Estimated cost: 0.000000  [input=0.000000, output=0.000000]\n"
     ]
    }
   ],
   "source": [
    "# After SQL generation\n",
    "maybe_print_checkpoint(\"After SQL generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb4769",
   "metadata": {},
   "source": [
    "## Optional reasoning step\n",
    "Ask the model to outline a brief plan before SQL generation. Useful for transparency in demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd523e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Reasoning function\n",
    "\n",
    "def generate_reasoning(intent_entities: str) -> str:\n",
    "    schema = get_schema_ctx()\n",
    "    if USING_REASONING:\n",
    "        prompt_text = REASONING_PROMPT_TEXT.format(schema=schema, intent_entities=intent_entities)\n",
    "        messages = [{ 'role': 'user', 'content': prompt_text.strip() }]\n",
    "        return _azure_chat_completions(messages, max_completion_tokens=8192)\n",
    "    chain = reasoning_prompt | llm\n",
    "    res = chain.invoke({'schema': schema, 'intent_entities': intent_entities})\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eff17a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== After SQL sanitization ====\n",
      "\n",
      "==== TOKEN USAGE (cumulative) ====\n",
      "Input tokens: 0\n",
      "Completion tokens: 0\n",
      "Total tokens: 0\n",
      "==== COST ESTIMATE ====\n",
      "Currency: USD\n",
      "Per-1K prices (input=0.00125, output=0.01) [source=file:azure_openai_pricing.json]\n",
      "Estimated cost: 0.000000  [input=0.000000, output=0.000000]\n"
     ]
    }
   ],
   "source": [
    "# After SQL sanitization\n",
    "maybe_print_checkpoint(\"After SQL sanitization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffc8fd",
   "metadata": {},
   "source": [
    "## SQL generation\n",
    "Generate T-SQL for the given intent/entities and schema context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc085498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) SQL generation function\n",
    "\n",
    "def generate_sql(intent_entities: str) -> str:\n",
    "    schema = get_schema_ctx()\n",
    "    if USING_REASONING:\n",
    "        prompt_text = SQL_PROMPT_TEXT.format(schema=schema, intent_entities=intent_entities)\n",
    "        messages = [{ 'role': 'user', 'content': prompt_text.strip() }]\n",
    "        return _azure_chat_completions(messages, max_completion_tokens=8192)\n",
    "    chain = sql_prompt | llm\n",
    "    result = chain.invoke({'schema': schema, 'intent_entities': intent_entities})\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed929fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== After execution/skip ====\n",
      "\n",
      "==== TOKEN USAGE (cumulative) ====\n",
      "Input tokens: 0\n",
      "Completion tokens: 0\n",
      "Total tokens: 0\n",
      "==== COST ESTIMATE ====\n",
      "Currency: USD\n",
      "Per-1K prices (input=0.00125, output=0.01) [source=file:azure_openai_pricing.json]\n",
      "Estimated cost: 0.000000  [input=0.000000, output=0.000000]\n"
     ]
    }
   ],
   "source": [
    "# After execution or skip\n",
    "maybe_print_checkpoint(\"After execution/skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218955ba",
   "metadata": {},
   "source": [
    "## SQL sanitization\n",
    "Extract only the executable SQL portion and normalize quotes for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4440cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) SQL sanitization\n",
    "\n",
    "def extract_and_sanitize_sql(raw_sql: str) -> str:\n",
    "    sql_code = raw_sql\n",
    "    # Prefer fenced code blocks if present (captures full content, e.g., WITH ...)\n",
    "    m = re.search(r\"```sql\\s*([\\s\\S]+?)```\", raw_sql, re.IGNORECASE)\n",
    "    if not m:\n",
    "        m = re.search(r\"```([\\s\\S]+?)```\", raw_sql)\n",
    "    if m:\n",
    "        sql_code = m.group(1).strip()\n",
    "    else:\n",
    "        # If a CTE exists, start from WITH to capture the entire statement\n",
    "        with_m = re.search(r\"(?is)\\bWITH\\b\\s+[A-Za-z0-9_\\[\\]]+\\s+AS\\s*\\(\", raw_sql)\n",
    "        if with_m:\n",
    "            sql_code = raw_sql[with_m.start():].strip()\n",
    "        else:\n",
    "            # Fallback to first SELECT\n",
    "            m2 = re.search(r\"(?is)\\bSELECT\\b[\\s\\S]+\", raw_sql)\n",
    "            if m2:\n",
    "                sql_code = m2.group(0).strip()\n",
    "            else:\n",
    "                sql_code = raw_sql.strip()\n",
    "    return (sql_code\n",
    "            .replace('’', \"'\")\n",
    "            .replace('‘', \"'\")\n",
    "            .replace('“', '\"')\n",
    "            .replace('”', '\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ae6a6",
   "metadata": {},
   "source": [
    "## Execution (optional)\n",
    "Use `sql_executor.execute_sql_query` to run against Azure SQL. Keep NO_EXEC=True for dry runs during demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5ab8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) SQL execution helpers (definitions only)\n",
    "\n",
    "def _safe_import_sql_executor():\n",
    "    repo_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()) == 'docs' else os.getcwd()\n",
    "    if repo_root not in sys.path:\n",
    "        sys.path.insert(0, repo_root)\n",
    "    try:\n",
    "        from sql_executor import execute_sql_query  # type: ignore\n",
    "        return execute_sql_query\n",
    "    except Exception as e:\n",
    "        raise ImportError('Unable to import execute_sql_query from sql_executor.py') from e\n",
    "\n",
    "\n",
    "def _format_table(rows):\n",
    "    if not rows:\n",
    "        return 'No results returned.\\n', []\n",
    "    columns = list(rows[0].keys())\n",
    "    col_widths = {c: max(len(c), max(len(str(r[c])) for r in rows)) for c in columns}\n",
    "    header = ' | '.join(c.ljust(col_widths[c]) for c in columns)\n",
    "    sep = '-+-'.join('-' * col_widths[c] for c in columns)\n",
    "    lines = [header, sep]\n",
    "    for r in rows:\n",
    "        lines.append(' | '.join(str(r[c]).ljust(col_widths[c]) for c in columns))\n",
    "    return ('\\n'.join(lines) + '\\n', [header, sep] + [' | '.join(str(r[c]).ljust(col_widths[c]) for c in columns) for r in rows])\n",
    "\n",
    "# Note: Execution is controlled by the global NO_EXEC flag in the Demo settings cell.\n",
    "# This cell only defines helpers; the end-to-end runner performs the actual execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e42e9f",
   "metadata": {},
   "source": [
    "## End-to-end demo cell\n",
    "Update toggles (`REFRESH_SCHEMA`, `SHOW_REASONING`, `NO_EXEC`) and `test_query` above as needed.\n",
    "Run this cell to repeat the flow with a different question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccc69c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINTENT ENTITIES:\n",
      "{\n",
      "  \"intent\": \"compute_aggregation\",\n",
      "  \"entities\": {\n",
      "    \"metric\": \"interest_rate\",\n",
      "    \"aggregation\": \"weighted_average\",\n",
      "    \"weight_field\": null,\n",
      "    \"group_by\": [\"region\"],\n",
      "    \"filters\": [],\n",
      "    ...\u001b[0m\n",
      "\n",
      "\u001b[96mREASONING:\n",
      "- Entities mapping: Metric = InterestRatePct; Weight = PrincipalAmount; Group by = RegionName.\n",
      "- Tables/Joins: Use dbo.vw_LoanPortfolio (preferred for portfolio metrics). No joins needed since RegionName, InterestRatePct, and PrincipalAmount exist in the view.\n",
      "- Aggregations: Compute weighted average interest rate per region as sum(InterestRatePct * PrincipalAmount) / sum(PrincipalAmount). Guard against divide-by-zero by excluding groups with zero principal.\n",
      "- Filters: None specified; include all loans in the view. Optionally exclude loans with NULL InterestRatePct or PrincipalAmount.\n",
      "- Order/Limit: None specified; default to ordering by RegionName for readability; no limit.\n",
      "- Assumptions: Use RegionName from the view to represent “region.” Interest rates are already in percentage terms (no FX needed). If portfolio convention is to use active loans only, add Status = 'Active'; otherwise include all.\u001b[0m\n",
      "\n",
      "\u001b[97mRAW SQL (truncated):\n",
      "SELECT\n",
      "  lp.RegionName,\n",
      "  SUM(CAST(lp.InterestRatePct * lp.PrincipalAmount AS decimal(38,10))) / NULLIF(SUM(CAST(lp.PrincipalAmount AS decimal(38,10))), 0) AS WeightedAvgInterestRatePct\n",
      "FROM dbo.vw_LoanPortfolio AS lp\n",
      "WHERE lp.PrincipalAmount > 0\n",
      "  AND lp.InterestRatePct IS NOT NULL\n",
      "GROUP BY lp.RegionName\u001b[0m\n",
      "\n",
      "\u001b[38;5;250mSANITIZED SQL:\n",
      "SELECT\n",
      "  lp.RegionName,\n",
      "  SUM(CAST(lp.InterestRatePct * lp.PrincipalAmount AS decimal(38,10))) / NULLIF(SUM(CAST(lp.PrincipalAmount AS decimal(38,10))), 0) AS WeightedAvgInterestRatePct\n",
      "FROM dbo.vw_LoanPortfolio AS lp\n",
      "WHERE lp.PrincipalAmount > 0\n",
      "  AND lp.InterestRatePct IS NOT NULL\n",
      "GROUP BY lp.RegionName\u001b[0m\n",
      "\n",
      "\u001b[38;5;220mRESULTS:\n",
      "RegionName | WeightedAvgInterestRatePct\n",
      "-----------+---------------------------\n",
      "Africa     | 9.500000                  \n",
      "Americas   | 6.166666                  \n",
      "Asia       | 3.900000                  \n",
      "Europe     | 4.750000                  \n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9) Rerun flow with another question (single, hardened output)\n",
    "\n",
    "# Global and per-cell guards to prevent duplicate section prints\n",
    "PRINTED_SECTIONS = globals().get('PRINTED_SECTIONS', {})  # persists across cells/runs in this kernel\n",
    "_printed_labels = set()  # per-execution guard\n",
    "\n",
    "def print_once(label: str, content: str, color: str):\n",
    "    # If this label already printed in this cell execution, skip\n",
    "    if label in _printed_labels:\n",
    "        return\n",
    "    # If we've already printed the exact same content for this label in this kernel session, skip\n",
    "    if PRINTED_SECTIONS.get(label) == (content or ''):\n",
    "        return\n",
    "    _printed_labels.add(label)\n",
    "    PRINTED_SECTIONS[label] = (content or '')\n",
    "    print_colored_block(label, content, color)\n",
    "\n",
    "# Pick your test query (uses global default unless you set a new one here)\n",
    "user_query = default_test_query\n",
    "\n",
    "# 1) Intent/entities\n",
    "intent_entities = parse_nl_query(user_query)\n",
    "if SHOW_INTENT:\n",
    "    trimmed = intent_entities[:200] + ('...' if len(intent_entities) > 200 else '') if intent_entities else '[empty]'\n",
    "    print_once('INTENT ENTITIES:', trimmed, YELLOW)\n",
    "\n",
    "# 2) Optional reasoning\n",
    "if SHOW_REASONING:\n",
    "    try:\n",
    "        r = generate_reasoning(intent_entities)\n",
    "        r_clean = (r.strip() if (r and isinstance(r, str)) else '')\n",
    "        print_once('REASONING:', (r_clean if r_clean else '[no reasoning returned]'), LIGHT_BLUE)\n",
    "    except Exception as e:\n",
    "        print('[WARN] Reasoning step failed:', e)\n",
    "\n",
    "# 3) SQL generation with guard\n",
    "try:\n",
    "    raw_sql = generate_sql(intent_entities)\n",
    "except Exception as e:\n",
    "    raw_sql = ''\n",
    "    print('[ERROR] SQL generation failed:', e)\n",
    "\n",
    "if not raw_sql or not raw_sql.strip():\n",
    "    print_once('RAW SQL (truncated):', '[empty]', WHITE)\n",
    "    sql_to_run = ''\n",
    "    print_once('SANITIZED SQL:', '[empty]', LIGHT_GRAY)\n",
    "else:\n",
    "    raw_trimmed = (raw_sql[:500] + '...') if len(raw_sql) > 500 else raw_sql\n",
    "    print_once('RAW SQL (truncated):', raw_trimmed, WHITE)\n",
    "    sql_to_run = extract_and_sanitize_sql(raw_sql)\n",
    "    print_once('SANITIZED SQL:', sql_to_run, LIGHT_GRAY)\n",
    "\n",
    "# 4) Execution with safety checks\n",
    "if not NO_EXEC:\n",
    "    sql_final = sql_to_run if 'sql_to_run' in locals() else ''\n",
    "    if not sql_final or not sql_final.strip():\n",
    "        print('[INFO] Skipping execution: SQL is empty.')\n",
    "    elif not re.search(r'\\bselect\\b', sql_final, re.IGNORECASE):\n",
    "        print('[INFO] Skipping execution: No SELECT statement detected.')\n",
    "    else:\n",
    "        try:\n",
    "            execute_sql_query = _safe_import_sql_executor()\n",
    "            rows = execute_sql_query(sql_final)\n",
    "            table_text, _ = _format_table(rows)\n",
    "            print_once('RESULTS:', table_text, GOLD)\n",
    "        except Exception as e:\n",
    "            print('[ERROR] Query failed:', e)\n",
    "else:\n",
    "    print('[INFO] Execution skipped (NO_EXEC=True)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8442dc",
   "metadata": {},
   "source": [
    "## Token usage and pricing setup\n",
    "This section adds lightweight helpers to capture token usage from Azure OpenAI responses and estimate cost in USD or CAD using `azure_openai_pricing.json` or environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "780af496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers to track token usage and compute cost in the notebook\n",
    "import os, json\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# Accumulator\n",
    "TOKEN_USAGE = {\"prompt\": 0, \"completion\": 0, \"total\": 0}\n",
    "\n",
    "def accumulate_usage(usage: Optional[Dict[str, Any]]):\n",
    "    if not usage:\n",
    "        return\n",
    "    TOKEN_USAGE[\"prompt\"] += int(usage.get(\"prompt_tokens\", 0) or 0)\n",
    "    TOKEN_USAGE[\"completion\"] += int(usage.get(\"completion_tokens\", 0) or 0)\n",
    "    if usage.get(\"total_tokens\") is not None:\n",
    "        TOKEN_USAGE[\"total\"] += int(usage.get(\"total_tokens\") or 0)\n",
    "    else:\n",
    "        TOKEN_USAGE[\"total\"] = TOKEN_USAGE[\"prompt\"] + TOKEN_USAGE[\"completion\"]\n",
    "\n",
    "def normalize_dep(name: str) -> str:\n",
    "    import re\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"_\", (name or \"\")).upper().strip(\"_\")\n",
    "\n",
    "def load_pricing() -> Dict[str, Dict[str, Any]]:\n",
    "    cfg_path = Path.cwd().parent / \"azure_openai_pricing.json\" if Path.cwd().name == \"docs\" else Path.cwd() / \"azure_openai_pricing.json\"\n",
    "    if cfg_path.exists():\n",
    "        try:\n",
    "            return json.loads(cfg_path.read_text())\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def get_target_currency() -> str:\n",
    "    cur = (os.getenv(\"AZURE_OPENAI_PRICE_CURRENCY\", \"USD\") or \"USD\").upper()\n",
    "    return cur if cur in (\"USD\", \"CAD\") else \"USD\"\n",
    "\n",
    "def convert_currency(amount: float, from_cur: str, to_cur: str) -> Optional[float]:\n",
    "    if from_cur == to_cur:\n",
    "        return amount\n",
    "    if from_cur == \"USD\" and to_cur == \"CAD\":\n",
    "        rate = os.getenv(\"AZURE_OPENAI_PRICE_USD_TO_CAD\")\n",
    "        return amount * float(rate) if rate else None\n",
    "    if from_cur == \"CAD\" and to_cur == \"USD\":\n",
    "        rate = os.getenv(\"AZURE_OPENAI_PRICE_CAD_TO_USD\")\n",
    "        return amount * float(rate) if rate else None\n",
    "    return None\n",
    "\n",
    "def get_pricing_for_deployment(dep_name: Optional[str]) -> Tuple[Optional[float], Optional[float], str, str]:\n",
    "    dep = dep_name or \"\"\n",
    "    dep_key = normalize_dep(dep)\n",
    "    target = get_target_currency()\n",
    "\n",
    "    # 1) Deployment-specific env\n",
    "    in_env = os.getenv(f\"AZURE_OPENAI_PRICE_{dep_key}_INPUT_PER_1K\")\n",
    "    out_env = os.getenv(f\"AZURE_OPENAI_PRICE_{dep_key}_OUTPUT_PER_1K\")\n",
    "    if in_env and out_env:\n",
    "        try:\n",
    "            return float(in_env), float(out_env), f\"env:{dep_key}\", target\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 2) Global env\n",
    "    in_glob = os.getenv(\"AZURE_OPENAI_PRICE_INPUT_PER_1K\")\n",
    "    out_glob = os.getenv(\"AZURE_OPENAI_PRICE_OUTPUT_PER_1K\")\n",
    "    if in_glob and out_glob:\n",
    "        try:\n",
    "            return float(in_glob), float(out_glob), \"env:global\", target\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 3) JSON\n",
    "    pm = load_pricing()\n",
    "    entry = pm.get(dep.lower()) or pm.get(dep)\n",
    "    if isinstance(entry, dict):\n",
    "        # nested per-currency first\n",
    "        cur_block = entry.get(target) if target in (\"USD\",\"CAD\") else None\n",
    "        if isinstance(cur_block, dict) and \"input_per_1k\" in cur_block and \"output_per_1k\" in cur_block:\n",
    "            try:\n",
    "                return float(cur_block[\"input_per_1k\"]), float(cur_block[\"output_per_1k\"]), \"file:azure_openai_pricing.json\", target\n",
    "            except Exception:\n",
    "                pass\n",
    "        # flat legacy (assume USD)\n",
    "        if \"input_per_1k\" in entry and \"output_per_1k\" in entry:\n",
    "            try:\n",
    "                in_usd = float(entry[\"input_per_1k\"])\n",
    "                out_usd = float(entry[\"output_per_1k\"])\n",
    "                if target == \"USD\":\n",
    "                    return in_usd, out_usd, \"file:azure_openai_pricing.json\", \"USD\"\n",
    "                i = convert_currency(in_usd, \"USD\", target)\n",
    "                o = convert_currency(out_usd, \"USD\", target)\n",
    "                if i is not None and o is not None:\n",
    "                    return i, o, \"file:azure_openai_pricing.json (converted)\", target\n",
    "                return in_usd, out_usd, \"file:azure_openai_pricing.json (USD; no conversion)\", \"USD\"\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None, None, \"unset\", target\n",
    "\n",
    "def print_usage_and_cost(dep_name: Optional[str], header: Optional[str] = None):\n",
    "    in_p, out_p, src, cur = get_pricing_for_deployment(dep_name)\n",
    "    pt = TOKEN_USAGE[\"prompt\"]\n",
    "    ct = TOKEN_USAGE[\"completion\"]\n",
    "    tt = TOKEN_USAGE[\"total\"] or (pt + ct)\n",
    "    if header:\n",
    "        print(f\"\\n==== {header} ====\")\n",
    "    print(\"\\n==== TOKEN USAGE ====\")\n",
    "    print(f\"Input tokens: {pt}\")\n",
    "    print(f\"Completion tokens: {ct}\")\n",
    "    print(f\"Total tokens: {tt}\")\n",
    "    if in_p is not None and out_p is not None:\n",
    "        ic = (pt/1000.0) * in_p\n",
    "        oc = (ct/1000.0) * out_p\n",
    "        tc = ic + oc\n",
    "        print(\"==== COST ESTIMATE ====\")\n",
    "        print(f\"Currency: {cur}\")\n",
    "        print(f\"Per-1K prices (input={in_p}, output={out_p}) [source={src}]\")\n",
    "        print(f\"Estimated cost: {tc:.6f}  [input={ic:.6f}, output={oc:.6f}]\")\n",
    "    else:\n",
    "        print(\"[INFO] Pricing not configured. Set AZURE_OPENAI_PRICE_* env vars or azure_openai_pricing.json.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fc716",
   "metadata": {},
   "source": [
    "### Capture usage from responses\n",
    "Below we add small wrappers to capture usage from the REST responses (reasoning/o-series path) and from LangChain responses (non-reasoning path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a04fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_usage_from_rest(resp_json: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    return resp_json.get(\"usage\") if isinstance(resp_json, dict) else None\n",
    "\n",
    "def extract_usage_from_langchain(ai_msg: Any) -> Optional[Dict[str, Any]]:\n",
    "    try:\n",
    "        meta = getattr(ai_msg, \"response_metadata\", None) or {}\n",
    "        tu = meta.get(\"token_usage\")\n",
    "        if isinstance(tu, dict):\n",
    "            return {\n",
    "                \"prompt_tokens\": tu.get(\"prompt_tokens\") or tu.get(\"input_tokens\") or 0,\n",
    "                \"completion_tokens\": tu.get(\"completion_tokens\") or tu.get(\"output_tokens\") or 0,\n",
    "                \"total_tokens\": tu.get(\"total_tokens\") or (tu.get(\"prompt_tokens\", 0) or 0) + (tu.get(\"completion_tokens\", 0) or 0),\n",
    "            }\n",
    "        um = getattr(ai_msg, \"usage_metadata\", None)\n",
    "        if isinstance(um, dict):\n",
    "            return {\n",
    "                \"prompt_tokens\": um.get(\"input_tokens\") or um.get(\"prompt_tokens\") or 0,\n",
    "                \"completion_tokens\": um.get(\"output_tokens\") or um.get(\"completion_tokens\") or 0,\n",
    "                \"total_tokens\": um.get(\"total_tokens\") or (um.get(\"input_tokens\", 0) or 0) + (um.get(\"output_tokens\", 0) or 0),\n",
    "            }\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5537f",
   "metadata": {},
   "source": [
    "### Example: run a single NL→SQL and then print usage and cost\n",
    "Use the same DEPLOYMENT_NAME already set in the notebook for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05303fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[demo] Skipped (set RUN_DEMO=True to enable this demo cell).\n"
     ]
    }
   ],
   "source": [
    "# Demo: prompt → reasoning (optional) → sql, capturing usage (gated)\n",
    "RUN_DEMO = globals().get('RUN_DEMO', False)\n",
    "if not RUN_DEMO:\n",
    "    print(\"[demo] Skipped (set RUN_DEMO=True to enable this demo cell).\")\n",
    "else:\n",
    "    demo_question = \"Show the 10 most recent loans\"\n",
    "    print(f\"Question: {demo_question}\")\n",
    "\n",
    "    # Reasoning-like deployments (o*/gpt-5) use REST in the notebook as well, if llm is None\n",
    "    if llm is None and USING_REASONING:\n",
    "        import requests\n",
    "        prompt_text = INTENT_PROMPT_TEXT.format(input=demo_question)\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text.strip()}]\n",
    "        url = f\"{ENDPOINT.rstrip('/')}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "        payload = {\"messages\": messages}\n",
    "        headers = {\"api-key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        accumulate_usage(extract_usage_from_rest(data))\n",
    "    else:\n",
    "        # Non-reasoning path via LangChain already set up in this notebook\n",
    "        res = intent_prompt | llm\n",
    "        msg = res.invoke({\"input\": demo_question})\n",
    "        content = msg.content\n",
    "        accumulate_usage(extract_usage_from_langchain(msg))\n",
    "\n",
    "    print(\"Intent & Entities:\\n\", content, \"\\n\")\n",
    "\n",
    "    # Generate SQL using the notebook's flow variables\n",
    "    schema_preview = schema_preview  # assumed from earlier cells\n",
    "    if llm is None and USING_REASONING:\n",
    "        import requests\n",
    "        prompt_text = SQL_PROMPT_TEXT.format(schema=schema_preview, intent_entities=content)\n",
    "        messages = [{\"role\":\"user\",\"content\": prompt_text.strip()}]\n",
    "        url = f\"{ENDPOINT.rstrip('/')}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "        payload = {\"messages\": messages}\n",
    "        headers = {\"api-key\": API_KEY, \"Content-Type\": \"application/json\"}\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        raw_sql = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        accumulate_usage(extract_usage_from_rest(data))\n",
    "    else:\n",
    "        res = (sql_prompt | llm).invoke({\"schema\": schema_preview, \"intent_entities\": content})\n",
    "        raw_sql = res.content\n",
    "        accumulate_usage(extract_usage_from_langchain(res))\n",
    "\n",
    "    print(\"Generated SQL (raw):\\n\", raw_sql)\n",
    "\n",
    "    # Print token usage and estimated cost (uses DEPLOYMENT_NAME from earlier setup)\n",
    "    print_usage_and_cost(DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2f6f5",
   "metadata": {},
   "source": [
    "## Final summary: token usage, cost, and run duration\n",
    "Toggle `SHOW_COSTS` to control checkpoint verbosity; the final summary always prints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b2669da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Summary setup] SHOW_COSTS= True\n"
     ]
    }
   ],
   "source": [
    "# Gate verbosity for checkpoints; final summary always prints\n",
    "SHOW_COSTS = True  # set to False to suppress intermediate checkpoint prints\n",
    "\n",
    "import time\n",
    "if 'RUN_START_TS' not in globals():\n",
    "    RUN_START_TS = time.time()\n",
    "\n",
    "def maybe_print_checkpoint(header: str):\n",
    "    if SHOW_COSTS:\n",
    "        print_usage_and_cost(DEPLOYMENT_NAME, header=header)\n",
    "\n",
    "# You can also call maybe_print_checkpoint(\"After some step\") manually in earlier cells if desired\n",
    "print(\"[Summary setup] SHOW_COSTS=\", SHOW_COSTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5870784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Final cumulative totals ====\n",
      "\n",
      "==== TOKEN USAGE ====\n",
      "Input tokens: 0\n",
      "Completion tokens: 0\n",
      "Total tokens: 0\n",
      "==== COST ESTIMATE ====\n",
      "Currency: USD\n",
      "Per-1K prices (input=0.00125, output=0.01) [source=file:azure_openai_pricing.json]\n",
      "Estimated cost: 0.000000  [input=0.000000, output=0.000000]\n",
      "==== RUN DURATION ====\n",
      "Run duration: 32.39 seconds\n"
     ]
    }
   ],
   "source": [
    "# Final summary cell: always prints cumulative usage/cost and run duration\n",
    "import time\n",
    "duration = time.time() - RUN_START_TS if 'RUN_START_TS' in globals() else None\n",
    "print_usage_and_cost(DEPLOYMENT_NAME, header=\"Final cumulative totals\")\n",
    "if duration is not None:\n",
    "    print(\"==== RUN DURATION ====\")\n",
    "    print(f\"Run duration: {duration:.2f} seconds\")\n",
    "else:\n",
    "    print(\"[INFO] RUN_START_TS not set; duration unavailable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

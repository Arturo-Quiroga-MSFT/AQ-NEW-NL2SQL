{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fee43a8",
   "metadata": {},
   "source": [
    "# NL→SQL Demo Notebook (Azure OpenAI + Azure SQL)\n",
    "\n",
    "This notebook walks through the NL→Intent→SQL pipeline step by step (aligned with the project flowchart).\n",
    "Each code cell is paired with guidance to help you present or explore the pipeline (for TERADATA demo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db8c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and environment setup\n",
    "import os, re, sys, json, time\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Third-party\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load .env (expects Azure OpenAI + Azure SQL vars)\n",
    "load_dotenv()\n",
    "print('Environment loaded. Ready to configure Azure OpenAI and Azure SQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b587aa",
   "metadata": {},
   "source": [
    "## Azure OpenAI configuration & reasoning models note\n",
    "- o-series/GPT-5 reasoning models using Chat Completions do not support temperature/top_p, etc.\n",
    "- We detect such deployments and call the REST API directly, omitting unsupported params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaeeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI configuration\n",
    "API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "DEPLOYMENT_NAME = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION', '2025-04-01-preview')\n",
    "\n",
    "def _is_reasoning_like_model(deployment_name: str | None) -> bool:\n",
    "    name = (deployment_name or '').lower()\n",
    "    return name.startswith('o') or name.startswith('gpt-5')\n",
    "\n",
    "_USING_REASONING_STYLE = _is_reasoning_like_model(DEPLOYMENT_NAME)\n",
    "print('Using reasoning style:', _USING_REASONING_STYLE, '| Deployment:', DEPLOYMENT_NAME)\n",
    "\n",
    "# Direct Chat Completions for reasoning models (no temperature/top_p)\n",
    "import requests\n",
    "def _azure_chat_completions(messages: List[Dict[str, Any]], max_completion_tokens: int | None = None) -> str:\n",
    "    url = f\"{ENDPOINT.rstrip('/')}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "    payload: Dict[str, Any] = {'messages': messages}\n",
    "    if max_completion_tokens is not None:\n",
    "        payload['max_completion_tokens'] = max_completion_tokens\n",
    "    headers = {'api-key': API_KEY or '', 'Content-Type': 'application/json'}\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data['choices'][0]['message']['content']\n",
    "\n",
    "# LangChain wrapper for non-reasoning models\n",
    "def _make_llm():\n",
    "    if _USING_REASONING_STYLE:\n",
    "        return None\n",
    "    return AzureChatOpenAI(\n",
    "        openai_api_key=API_KEY,\n",
    "        azure_endpoint=ENDPOINT,\n",
    "        deployment_name=DEPLOYMENT_NAME,\n",
    "        api_version=API_VERSION,\n",
    "    )\n",
    "\n",
    "llm = _make_llm()\n",
    "print('LLM configured (None for reasoning models):', llm is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a986a",
   "metadata": {},
   "source": [
    "## Prompts and intent extraction (diagram: INTENT & ENTITIES)\n",
    "We maintain shared prompt text and pick the correct call-path (direct REST vs LangChain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt text\n",
    "INTENT_PROMPT_TEXT = (\n",
    "    \"\n",
    "    You are an expert in translating natural language to database queries. Extract the intent and entities from the following user input:\n",
    "    {input}\n",
    "    \"\n",
    " )\n",
    "SQL_PROMPT_TEXT = (\n",
    "    \"\n",
    "    You are an expert in SQL and Azure SQL Database. Given the following database schema and the intent/entities, generate a valid T-SQL query for querying the database.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Do NOT use USE statements (USE [database] is not supported in Azure SQL Database)\n",
    "    - Generate only the SELECT query without USE or GO statements\n",
    "    - Return only executable T-SQL code without markdown formatting\n",
    "    - The database connection is already established to the correct database\n",
    "\n",
    "    Schema:\n",
    "    {schema}\n",
    "    Intent and Entities:\n",
    "    {intent_entities}\n",
    "\n",
    "    Generate a T-SQL query that can be executed directly:\n",
    "    \"\n",
    " )\n",
    "REASONING_PROMPT_TEXT = (\n",
    "    \"\n",
    "    You are assisting with SQL generation. Before writing SQL, produce a short, high-level reasoning summary\n",
    "    for how you will construct the query, based on the schema and the intent/entities.\n",
    "\n",
    "    Rules:\n",
    "    - Do NOT include any SQL code.\n",
    "    - Keep it concise (<= 150 words) and actionable.\n",
    "    - Use simple bullets covering: Entities mapping, Tables/Joins, Aggregations (if any), Filters, Order/Limit, Assumptions.\n",
    "\n",
    "    Schema:\n",
    "    {schema}\n",
    "    Intent and Entities:\n",
    "    {intent_entities}\n",
    "\n",
    "    Provide the reasoning summary now:\n",
    "    \"\n",
    " )\n",
    "\n",
    "# Templates for LangChain path\n",
    "intent_prompt = ChatPromptTemplate.from_template(INTENT_PROMPT_TEXT)\n",
    "sql_prompt = ChatPromptTemplate.from_template(SQL_PROMPT_TEXT)\n",
    "reasoning_prompt = ChatPromptTemplate.from_template(REASONING_PROMPT_TEXT)\n",
    "\n",
    "def parse_nl_query(user_input: str) -> str:\n",
    "    if _USING_REASONING_STYLE:\n",
    "        prompt_text = INTENT_PROMPT_TEXT.format(input=user_input)\n",
    "        messages = [{ 'role': 'user', 'content': prompt_text.strip() }]\n",
    "        return _azure_chat_completions(messages, max_completion_tokens=800)\n",
    "    chain = intent_prompt | llm\n",
    "    res = chain.invoke({'input': user_input})\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2700535",
   "metadata": {},
   "source": [
    "## Schema context & optional refresh (diagram: REFRESH SCHEMA branch)\n",
    "The schema context steers SQL generation to real tables/columns. Optionally refresh the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e93827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe imports from this repository\n",
    "def _safe_import_schema_reader():\n",
    "    this_dir = os.path.dirname(__file__) if '__file__' in globals() else os.getcwd()\n",
    "    if this_dir and this_dir not in sys.path:\n",
    "        sys.path.insert(0, this_dir)\n",
    "    try:\n",
    "        from schema_reader import get_sql_database_schema_context  # type: ignore\n",
    "        return get_sql_database_schema_context\n",
    "    except Exception as e:\n",
    "        raise ImportError('Unable to import get_sql_database_schema_context from schema_reader.') from e\n",
    "\n",
    "# Optional: refresh the schema cache\n",
    "REFRESH_SCHEMA = False  # <- toggle for your demo\n",
    "if REFRESH_SCHEMA:\n",
    "    try:\n",
    "        import schema_reader\n",
    "        cache_path = schema_reader.refresh_schema_cache()\n",
    "        print('[INFO] Schema cache refreshed:', cache_path)\n",
    "    except Exception as e:\n",
    "        print('[WARN] Failed to refresh schema cache:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab31005",
   "metadata": {},
   "source": [
    "## Reasoning summary (optional)\n",
    "Ask the model for a short plan before generating SQL (skippable in faster runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reasoning(intent_entities: str) -> str:\n",
    "    get_schema_ctx = _safe_import_schema_reader()\n",
    "    schema = get_schema_ctx()\n",
    "    if _USING_REASONING_STYLE:\n",
    "        prompt_text = REASONING_PROMPT_TEXT.format(schema=schema, intent_entities=intent_entities)\n",
    "        messages = [{ 'role': 'user', 'content': prompt_text.strip() }]\n",
    "        return _azure_chat_completions(messages, max_completion_tokens=600)\n",
    "    chain = reasoning_prompt | llm\n",
    "    res = chain.invoke({'schema': schema, 'intent_entities': intent_entities})\n",
    "    return res.content\n",
    "\n",
    "# Demo variable (edit for your run)\n",
    "test_query = 'Show the 10 most recent loans'\n",
    "intent_entities = parse_nl_query(test_query)\n",
    "print('INTENT & ENTITIES:\n",
    "', intent_entities, '\n",
    "')\n",
    "\n",
    "SHOW_REASONING = True  # <- toggle for your demo\n",
    "if SHOW_REASONING:\n",
    "    reasoning = generate_reasoning(intent_entities)\n",
    "    print('SQL GENERATION REASONING:\n",
    "', reasoning, '\n",
    "')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91bfd98",
   "metadata": {},
   "source": [
    "## SQL generation (diagram: SQL GENERATION)\n",
    "Produce a T-SQL statement aligned with the extracted intent and schema context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(intent_entities: str) -> str:\n",
    "    get_schema_ctx = _safe_import_schema_reader()\n",
    "    schema = get_schema_ctx()\n",
    "    if _USING_REASONING_STYLE:\n",
    "        prompt_text = SQL_PROMPT_TEXT.format(schema=schema, intent_entities=intent_entities)\n",
    "        messages = [{ 'role': 'user', 'content': prompt_text.strip() }]\n",
    "        return _azure_chat_completions(messages, max_completion_tokens=1200)\n",
    "    chain = sql_prompt | llm\n",
    "    result = chain.invoke({'schema': schema, 'intent_entities': intent_entities})\n",
    "    return result.content\n",
    "\n",
    "raw_sql = generate_sql(intent_entities)\n",
    "print('GENERATED SQL (RAW):\n",
    "', raw_sql, '\n",
    "')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3506f4f",
   "metadata": {},
   "source": [
    "## SQL sanitization (diagram: SANITIZATION)\n",
    "Extract the SELECT code and normalize quotes for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_sanitize_sql(raw_sql: str) -> str:\n",
    "    sql_code = raw_sql\n",
    "    code_block = re.search(r\"```sql\\s*([\\s\\S]+?)```\", raw_sql, re.IGNORECASE)\n",
    "    if not code_block:\n",
    "        code_block = re.search(r\"```([\\s\\S]+?)```\", raw_sql)\n",
    "    if code_block:\n",
    "        sql_code = code_block.group(1).strip()\n",
    "    else:\n",
    "        select_match = re.search(r\"(SELECT[\\s\\S]+)\", raw_sql, re.IGNORECASE)\n",
    "        if select_match:\n",
    "            sql_code = select_match.group(1).strip()\n",
    "    return (\n",
    "        sql_code.replace('’', \n",
    ")\n",
    "                .replace('‘', \n",
    ")\n",
    "                .replace('“', '\n",
    ",\n",
    "')\n",
    "    )\n",
    "\n",
    "sql_to_run = extract_and_sanitize_sql(raw_sql)\n",
    "print('SANITIZED SQL (FOR EXECUTION):\n",
    "', sql_to_run, '\n",
    "')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae40479",
   "metadata": {},
   "source": [
    "## Execution (diagram: EXECUTION)\n",
    "Run the SQL against Azure SQL and format results (toggle NO_EXEC for dry runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_import_sql_executor():\n",
    "    this_dir = os.path.dirname(__file__) if '__file__' in globals() else os.getcwd()\n",
    "    if this_dir and this_dir not in sys.path:\n",
    "        sys.path.insert(0, this_dir)\n",
    "    try:\n",
    "        from sql_executor import execute_sql_query  # type: ignore\n",
    "        return execute_sql_query\n",
    "    except Exception as e:\n",
    "        raise ImportError('Unable to import execute_sql_query from sql_executor.') from e\n",
    "\n",
    "def _format_table(rows):\n",
    "    if not rows:\n",
    "        return 'No results returned.\n",
    "', []\n",
    "    columns = list(rows[0].keys())\n",
    "    col_widths = {c: max(len(c), max(len(str(r[c])) for r in rows)) for c in columns}\n",
    "    header = ' | '.join(c.ljust(col_widths[c]) for c in columns)\n",
    "    sep = '-+-'.join('-' * col_widths[c] for c in columns)\n",
    "    lines = [header, sep]\n",
    "    for r in rows:\n",
    "        lines.append(' | '.join(str(r[c]).ljust(col_widths[c]) for c in columns))\n",
    "    return (\n",
    "        '\n",
    "'.join(lines) + '\n",
    "',\n",
    "        [header, sep] + [' | '.join(str(r[c]).ljust(col_widths[c]) for c in columns) for r in rows]\n",
    "    )\n",
    "\n",
    "NO_EXEC = True  # <- toggle for your demo\n",
    "if not NO_EXEC:\n",
    "    try:\n",
    "        execute_sql_query = _safe_import_sql_executor()\n",
    "        rows = execute_sql_query(sql_to_run)\n",
    "        table_text, _ = _format_table(rows)\n",
    "        print('SQL QUERY RESULTS (TABLE):\n",
    "' + table_text)\n",
    "    except Exception as e:\n",
    "        print('[ERROR] Failed to execute SQL query:', e)\n",
    "else:\n",
    "    print('[INFO] Execution skipped (NO_EXEC=True)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e7e810",
   "metadata": {},
   "source": [
    "## End-to-end runner cell (adjust toggles)\n",
    "Change `test_query`, `REFRESH_SCHEMA`, `SHOW_REASONING`, and `NO_EXEC` above and re-run cells.\n",
    "This cell illustrates the typical order: Input → Intent → (Reasoning) → SQL → Sanitize → (Execute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: run the entire flow again with a different query\n",
    "test_query = 'For each region, list the top 5 companies by balance'\n",
    "intent_entities = parse_nl_query(test_query)\n",
    "print('INTENT & ENTITIES:\n",
    "', intent_entities, '\n",
    "')\n",
    "\n",
    "if SHOW_REASONING:\n",
    "    print('SQL GENERATION REASONING:\n",
    "', generate_reasoning(intent_entities), '\n",
    "')\n",
    "\n",
    "raw_sql = generate_sql(intent_entities)\n",
    "print('GENERATED SQL (RAW):\n",
    "', raw_sql, '\n",
    "')\n",
    "\n",
    "sql_to_run = extract_and_sanitize_sql(raw_sql)\n",
    "print('SANITIZED SQL (FOR EXECUTION):\n",
    "', sql_to_run, '\n",
    "')\n",
    "\n",
    "if not NO_EXEC:\n",
    "    try:\n",
    "        execute_sql_query = _safe_import_sql_executor()\n",
    "        rows = execute_sql_query(sql_to_run)\n",
    "        table_text, _ = _format_table(rows)\n",
    "        print('SQL QUERY RESULTS (TABLE):\n",
    "' + table_text)\n",
    "    except Exception as e:\n",
    "        print('[ERROR] Failed to execute SQL query:', e)\n",
    "else:\n",
    "    print('[INFO] Execution skipped (NO_EXEC=True)')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
